- name: Pieter Roelfsema
  url: https://nin.nl/about-us/the-organisation/team/pieter-roelfsema/
  photo: PR.jpg
  affil: Department Head, Netherlands Institute for Neuroscience
  talk_title: "BrainProp: How Attentional Processes in the Brain Solve the Credit Assignment Problem"
  talk_abstract: "Humans and many other animals have an enormous capacity to learn about sensory stimuli and to master new skills. Many of the mechanisms that enable us to learn remain to be understood. One of the greatest challenges of systems neuroscience is to explain how synaptic connections change to support maximally adaptive behaviour. We will provide an overview of factors that determine the change in the strength of synapses. Specifically, we will discuss the influence of attention, neuromodulators and feedback connections in synaptic plasticity and suggest a specific framework, called BrainProp, in which these factors interact to improve the functioning of the entire network.


Much recent work focuses on learning in the brain using presumed biologically plausible variants of supervised learning algorithms. However, the biological plausibility of these approaches is limited, because there is no teacher in the motor cortex that instructs the motor neurons. Instead, learning in the brain usually depends on reward and punishment. BrainProp is a biologically plausible reinforcement learning scheme for deep networks with an any number of layers. The network chooses an action by selecting a unit in the output layer and uses feedback connections to assign credit to the units in lower layers that are responsible for this action. After the choice, the network receives reinforcement so that there is no need for a teacher. We showed how BrainProp is mathematically equivalent to error backpropagation, for one output unit at a time (Pozzi et al., 2020). We illustrate learning of classical and hard image-classification benchmarks (MNIST, CIFAR10, CIFAR100 and Tiny ImageNet) by deep networks. BrainProp achieves an accuracy that is equivalent to that of standard error-backpropagation, and better than other state-of-the-art biologically inspired learning schemes. Additionally, the trial-and-error nature of learning is associated with limited additional training time so that BrainProp is a factor of 1-3.5 times slower. These results provide new insights into how deep learning may be implemented in the brain."
  category: speakers
  panelist: false

- name: Ida Momennejad
  url: https://www.momen-nejad.org/
  photo: IM.jpg
  affil: Principal Researcher, Microsoft Research
  # talk_title: TBA
  # talk_abstract: TBA
  category: speakers
  panelist: true

- name: James Whittington
  url: https://www.jcrwhittington.com/
  photo: JW.jpg
  affil: Postdoc, University of Oxford
  talk_title: "Relating Transformers to Models and Neural Representations of the Hippocampal Formation"
  talk_abstract: "Many deep neural network architectures loosely based on brain networks have recently been shown to replicate neural firing patterns observed in the brain. One of the most exciting and promising novel architectures, the Transformer neural network, was developed without the brain in mind. In this work, we show that transformers, when equipped with recurrent position encodings, replicate the precisely tuned spatial representations of the hippocampal formation; most notably place and grid cells. Furthermore, we show that this result is no surprise since it is closely related to current hippocampal models from neuroscience. We additionally show the transformer version offers dramatic performance gains over the neuroscience version. This work continues to bind computations of artificial and brain networks, offers a novel understanding of the hippocampal-cortical interaction, and suggests how wider cortical areas may perform complex tasks beyond current neuroscience models such as language comprehension."
  category: speakers
  panelist: true

- name: Henny Admoni
  url: https://www.hennyadmoni.com/
  photo: HA.png
  affil: A. Nico Habermann Assistant Professor, Carnegie Mellon University
  talk_title: Eye Gaze in Human-Robot Collaboration
  talk_abstract: "In robotics, human-robot collaboration works best when robots are responsive to their human partners' mental states. Human eye gaze has been used as a proxy for one such mental state: attention. While eye gaze can be a useful signal, for example enabling intent prediction, it is also a noisy one. Gaze serves several functions beyond attention, and thus recognizing what people are attending to from their eye gaze is a complex task. In this talk, I will discuss our research on modeling eye gaze to understand human attention in collaborative tasks such as shared manipulation and assisted driving."
  category: speakers
  panelist: true

- name: Tobias Gerstenberg
  url: https://cicl.stanford.edu/member/tobias_gerstenberg/
  photo: TG.jpg
  affil: Assistant Professor of Cognitive Psychology, Stanford University
  # talk_title: TBA
  # talk_abstract: TBA
  category: speakers
  panelist: true

- name: Vidhya Navalpakkam
  url: https://research.google/people/VidhyaNavalpakkam/
  photo: VN.jpg
  affil: Principal Scientist, Google Research
  # talk_title: TBA
  # talk_abstract: TBA
  category: speakers
  panelist: true

- name: Shalini De Mello
  url: https://research.nvidia.com/person/shalini-gupta
  photo: SM.jpg
  affil: Principal Research Scientist, NVIDIA
  # talk_title: TBA
  # talk_abstract: TBA
  category: speakers
  panelist: true

- name: Erin Grant
  url: https://eringrant.github.io/
  photo: EG.jpg
  affil: Ph. D. Candidate, UC Berkeley
  # talk_title: TBA
  # talk_abstract: TBA
  category: speakers
  panelist: true
